{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "3 issues found\n",
      "\n",
      "Converting page to PDF: https://github.com/jackjamieson2/yarns-indie-reader/issues/1\n",
      "Loading pages (1/6)\n",
      "Counting pages (2/6)                                               \n",
      "Resolving links (4/6)                                                       \n",
      "Loading headers and footers (5/6)                                           \n",
      "Printing pages (6/6)\n",
      "Done                                                                      \n",
      "\n",
      "Converting page to PDF: https://github.com/jackjamieson2/yarns-indie-reader/issues/2\n",
      "Loading pages (1/6)\n",
      "Counting pages (2/6)                                               \n",
      "Resolving links (4/6)                                                       \n",
      "Loading headers and footers (5/6)                                           \n",
      "Printing pages (6/6)\n",
      "Done                                                                      \n",
      "\n",
      "Converting page to PDF: https://github.com/jackjamieson2/yarns-indie-reader/issues/3\n",
      "Loading pages (1/6)\n",
      "Counting pages (2/6)                                               \n",
      "Resolving links (4/6)                                                       \n",
      "Loading headers and footers (5/6)                                           \n",
      "Printing pages (6/6)\n",
      "Done                                                                      \n",
      "\n",
      "\n",
      "Finished!\n",
      "Saved PDFs for 3 issues.\n",
      "Find your exported PDFs in Exported PDFs/jackjamieson2/yarns-indie-reader/\n"
     ]
    }
   ],
   "source": [
    "### This script scrapes the issues for a github project, and saves each one as a PDF.\n",
    "\n",
    "import pdfkit\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# OPTIONS:\n",
    "\n",
    "# Repository to fetch from (e.g. jackjamieson2/GitHub-issues-to-pdf)\n",
    "repository = 'jackjamieson2/yarns-indie-reader'\n",
    "\n",
    "# Output directory to save PDFs\n",
    "output_dir = 'Exported PDFs/' + repository + \"/\"\n",
    "\n",
    "# Generate automatic tags  (True/False)\n",
    "generate_auto_tags = True   # If true will add automatically generated tags to \n",
    "                            # bottom of the PDF in the form ##[tag]. See autotags() function for details\n",
    "                        \n",
    "\n",
    "\n",
    "print(\"starting...\")\n",
    "# Autotags\n",
    "def autotags(soup):\n",
    "    referenced = False\n",
    "    commit_found = False\n",
    "    tags = \"<br><h1>Tags</h1>\"\n",
    "    tags+=\"<br>###status: \" + soup.select(\".TableObject-item .State\")[0].text\n",
    "\n",
    "    for item in soup.select('.discussion-item'):\n",
    "        if str(item).find('This was referenced')>=0:\n",
    "            referenced = True\n",
    "        if str(item).find('referenced this issue')>=0:\n",
    "            referenced = True\n",
    "        if str(item).find('id=\"ref-commit-')>=0:\n",
    "            commit_found = True\n",
    "    if referenced == True:\n",
    "        tags+=\"<br>###referenced\"\n",
    "    if commit_found == True:\n",
    "        tags+=\"<br>###referenced_in_commit\"\n",
    "           \n",
    "    for item in soup.select('.labels a'):\n",
    "        tags+=\"<br>###current_label: \" + item.text\n",
    "    \n",
    "    for item in soup.select('.IssueLabel a'):\n",
    "        tags+=\"<br>###past_or_present_label: \" + item.text\n",
    "            \n",
    "    participants_N = len(soup.select('.participant-avatar'))\n",
    "    if participants_N ==1:\n",
    "        tags+=\"<br>###1_participant\"\n",
    "    elif participants_N ==2:\n",
    "        tags+=\"<br>###2_participants\"\n",
    "    elif participants_N >2:\n",
    "        tags+=\"<br>###>=3_participants\" + \"(\" + str(participants_N) + \")\"\n",
    "            \n",
    "    for item in soup.select('.participant-avatar'):\n",
    "        participant_name = re.sub(\"/\",\"\",item.get('href'))\n",
    "        tags+=\"<br>###participant: \" + participant_name\n",
    "        \n",
    "    for item in soup.select('.assignee'):\n",
    "        tags+=\"<br>###assignee: \" + item.text\n",
    "          \n",
    "    return tags\n",
    "\n",
    "def log_error(error):   \n",
    "    if not os.path.isfile(output_dir + \"error_log.txt\"):\n",
    "        # Log file does not exist, so write explanatory header  \n",
    "        with open(output_dir + \"error_log.txt\", \"a\") as myfile:\n",
    "            myfile.write(\"Errors reported for the following URLs, please check to ensure the generated PDFs are correct.\")\n",
    "    with open(output_dir + \"error_log.txt\", \"a\") as myfile:\n",
    "        myfile.write(\"\\n\\n\" + str(datetime.now()) + \"\\n\" + error)\n",
    "        myfile.close()\n",
    "    return\n",
    " \n",
    "#Options\n",
    "options = {\n",
    "    'dpi':'300' # This zooms in to make the PDFs more readable (recommended) \n",
    "}\n",
    "\n",
    "# Look up how many issues the repository has\n",
    "issue_count = 0\n",
    "r = requests.get('https://github.com/' + repository + '/issues?q=is%3Aissue')\n",
    "if r.status_code == 200:\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "    issue = soup.find(class_=\"js-issue-row\")\n",
    "    issue_count = int(re.sub('issue_',\"\",issue.get('id')))\n",
    "    print(str(issue_count) + \" issues found\")\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    errors = []\n",
    "    # Iterate through each issue page\n",
    "    for i in range (1,issue_count +1):\n",
    "        url = 'https://github.com/' + repository + '/issues/' + str(i)\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            print('\\nConverting page to PDF: ' + url)\n",
    "            c = r.text\n",
    "            # Strip versioning number from <link> paths (e.g. example.css?1234 -> example.css)\n",
    "            # This is needed to avoid an error with wkpdftohtml\n",
    "            # see thread at https://github.com/wkhtmltopdf/wkhtmltopdf/issues/2051\n",
    "            html = re.sub('#(\\.css|\\.js)\\?[^\"]+#', '$1', c)\n",
    "            soup = BeautifulSoup(html, \"lxml\")\n",
    "            html_head = str(soup.head)\n",
    "            html_body = str(soup.find(class_='repohead'))\n",
    "            html_body = str(html_body) + str(soup.find(id='show_issue'))\n",
    "            if generate_auto_tags == True:\n",
    "                tags = autotags(soup)\n",
    "            else:\n",
    "                tags = \"\"\n",
    "            \n",
    "            full_html = html_head + html_body + tags\n",
    "\n",
    "            try:\n",
    "                if soup.find(id='show_issue'):\n",
    "                    pdfkit.from_string(full_html, output_dir +str(i) +'.pdf', options=options)\n",
    "                else:\n",
    "                    print('\\nIssue does not exist:' + url)\n",
    "            except:\n",
    "                log_error(url)\n",
    "\n",
    "                \n",
    "                \n",
    "        elif r.status_code == 404:\n",
    "            print('\\n404 not found: ' + url  )\n",
    "\n",
    "    print('\\n\\nFinished!\\nSaved PDFs for ' + str(i) + ' issues.' )\n",
    "    print('Find your exported PDFs in ' +output_dir )\n",
    "else:\n",
    "    print(\"Repository not found: \" + repository)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
